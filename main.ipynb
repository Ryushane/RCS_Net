{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Dim Incremental learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import ForwardRef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class OneDimNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneDimNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=10, kernel_size=3, stride=2) # length = 479\n",
    "        self.max_pool1=nn.MaxPool1d(kernel_size=3, stride=2) # length = 239\n",
    "        self.conv2=nn.Conv1d(10, 20, 3, 2) # length = 119\n",
    "        self.max_pool2 = nn.MaxPool1d(3, 2) # length = 59\n",
    "        self.conv3=nn.Conv1d(20, 40, 3, 2) # length = 29\n",
    "\n",
    "        self.liner1 = nn.Linear(40 * 14, 120)\n",
    "        self.liner2 = nn.Linear(120, 84)\n",
    "        self.liner3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "\n",
    "        x = x.view(-1, 40 * 14)\n",
    "        x = F.relu(self.liner1(x))\n",
    "        x = F.relu(self.liner2(x))\n",
    "        x = self.liner3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1=nn.Conv1d(20, 40, 3, 2) # length = 29\n",
    "input = torch.randn(1, 29, 20) # batch, length, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input.permute(0,2,1)\n",
    "input = Variable(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv1(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 14])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sin.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35172/3146827509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sin.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tri.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msqu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'squ.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msqu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sin.npy'"
     ]
    }
   ],
   "source": [
    "sin = np.array(np.load('sin.npy'))\n",
    "tri = np.array(np.load('tri.npy'))\n",
    "squ = np.array(np.load('squ.npy'))\n",
    "x = np.array([sin,tri,squ])\n",
    "x.shape\n",
    "y = np.array([[0],[1],[2]])\n",
    "y\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "## 这里写了一个简单的神经网络，方便理解\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# 效果不太好\n",
    "sin = np.array(np.load('data/sin.npy'))\n",
    "tri = np.array(np.load('data/tri.npy'))\n",
    "squ = np.array(np.load('data/squ.npy'))\n",
    "\n",
    "sin_30 = np.array(np.load('data/sin_30.npy'))\n",
    "tri_30 = np.array(np.load('data/tri_30.npy'))\n",
    "squ_30 = np.array(np.load('data/squ_30.npy'))\n",
    "# 构建输入集\n",
    "# x = np.mat('0 0;'\n",
    "#            '0 1;'\n",
    "#            '1 0;'\n",
    "#            '1 1')\n",
    "\n",
    "x = np.array([sin,tri,squ,sin_30,tri_30,squ_30])\n",
    "x = torch.tensor(x).float()\n",
    "y = np.array([[0],[1],[2],[0],[1],[2]])\n",
    "y = torch.tensor(y).float()\n",
    "\n",
    "\n",
    "\n",
    "# 搭建网络\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.cl1 = nn.Linear(256, 128)\n",
    "        self.cl2 = nn.Linear(128,10)\n",
    "        self.fc1 = nn.Linear(10,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cl1(x))\n",
    "        x = F.relu(self.cl2(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "myNet = MyModel()\n",
    "myNet.fc1.register_forward_hook(get_activation('fc1'))\n",
    "\n",
    "# 设置优化器\n",
    "optimzer = torch.optim.SGD(myNet.parameters(), lr=0.05)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "for epoch in range(5000):\n",
    "    out = myNet(x)\n",
    "    loss = loss_func(out, y)  # 计算误差\n",
    "    optimzer.zero_grad()  # 清除梯度\n",
    "    loss.backward()\n",
    "    optimzer.step()\n",
    "\n",
    "# print(activation['fc1'])\n",
    "\n",
    "print(myNet(x).data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "x = np.array(np.load('data/sin_31.npy'))\n",
    "x = torch.tensor(x).float()\n",
    "print(myNet(x).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "a.append(2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import ForwardRef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class OneDimNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneDimNet, self).__init__()\n",
    "        ## input = 1 x 227 x 1 (Row, Column, channel)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0) # weight of size [96, 1, 11] (out chan, in chan, ker_size)\n",
    "        self.max_pool1=nn.MaxPool1d(kernel_size=3, stride=2) # length = \n",
    "        self.conv2=nn.Conv1d(96, 256, 5, 1, 2) # length = 119\n",
    "        self.max_pool2 = nn.MaxPool1d(3, 2) # length = 59\n",
    "        self.conv3=nn.Conv1d(256, 384, 3, 1, 1) # length = 29\n",
    "        self.conv4=nn.Conv1d(384, 384, 3, 1, 1)\n",
    "        self.conv5=nn.Conv1d(384, 256, 3, 1, 1)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.liner1(x))\n",
    "        x = F.relu(self.liner2(x))\n",
    "        x = self.liner3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features\n",
    "\n",
    "    # optimzer = torch.optim.SGD(OneDimNet.parameters(), lr=0.05)\n",
    "    # loss_func = nn.MSELoss()\n",
    "\n",
    "    # for epoch in range(5000):\n",
    "    #     out = OneDimNet(x)\n",
    "    #     loss = loss_func(out, y)  # 计算误差\n",
    "    #     optimzer.zero_grad()  # 清除梯度\n",
    "    #     loss.backward()\n",
    "    #     optimzer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneDimNet(\n",
      "  (conv1): Conv1d(1, 96, kernel_size=(11,), stride=(4,))\n",
      "  (max_pool1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(96, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (max_pool2): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(256, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv4): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv5): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "parameters() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35172/1889190559.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m227\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# batch, channel, Height, Width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0moptimzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOneDimNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: parameters() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "net=OneDimNet()\n",
    "print(net)\n",
    "\n",
    "input = Variable(torch.randn(3, 1, 227)) # batch, channel, Height, Width\n",
    "\n",
    "optimzer = torch.optim.SGD(OneDimNet.parameters(), lr=0.05)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for epoch in range(5000):\n",
    "    out = OneDimNet(x)\n",
    "    loss = loss_func(out, y)  # 计算误差\n",
    "    optimzer.zero_grad()  # 清除梯度\n",
    "    loss.backward()\n",
    "    optimzer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4788, -0.4595,  0.4206,  ...,  0.6415,  0.8621, -0.0820],\n",
      "         [ 0.9075,  0.7026, -0.4566,  ...,  0.8942, -0.3017, -0.0664],\n",
      "         [ 0.3873,  0.1756,  0.7099,  ...,  1.2519,  0.8428,  0.8790],\n",
      "         ...,\n",
      "         [ 0.4584,  0.7585,  0.8612,  ..., -0.2446, -0.0886,  0.2389],\n",
      "         [ 0.0897, -0.3149, -0.0532,  ..., -0.5106, -1.0129, -0.7503],\n",
      "         [-0.5296,  0.0194, -0.7537,  ...,  0.4335, -0.3794, -1.6667]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv1d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0) \n",
    "input = Variable(torch.randn(1, 1, 227)) # batch, channel, Height, Width\n",
    "out = conv1(input)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bc0b564b1123c528a87a484e5506920facf1ea01338cd3f6b589bbb0b589e01"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
